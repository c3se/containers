Bootstrap: docker
From: nvcr.io/nvidia/jax:25.01-py3

%arguments
    VERSION=3.0.1

%help
    Copyright 2024 DeepMind Technologies Limited

    AlphaFold 3 source code is licensed under CC BY-NC-SA 4.0. To view a copy of
    this license, visit https://creativecommons.org/licenses/by-nc-sa/4.0/

    To request access to the AlphaFold 3 model parameters, follow the process set
    out at https://github.com/google-deepmind/alphafold3. You may only use these
    if received directly from Google. Use is subject to terms of use available at
    https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md

%post
    # Update installers to be ready for installations
    apt-get update --yes --quiet
    pip3 install --upgrade pip

    # Install HMMER
    apt-get install --yes hmmer

    # Get the AlphaFold 3 source code
    mkdir /alphafold_build/
    cd /alphafold_build/
    wget https://github.com/google-deepmind/alphafold3/archive/refs/tags/v{{VERSION}}.tar.gz
    tar -xzf v{{VERSION}}.tar.gz
    rm v{{VERSION}}.tar.gz

    # Relax jax version requirements slightly and install alphafold3
    cd alphafold3-{{VERSION}}/
    sed -i -E 's/(jax[^=]*)==/\1~=/' pyproject.toml
    sed -i -E 's/(jax)\[cuda.*\]/\1/' pyproject.toml

    pip3 install .

    cat <(echo "#!/usr/bin/env python") run_alphafold.py > /usr/local/bin/run_alphafold.py
    chmod +x /usr/local/bin/run_alphafold.py

    rm -R /alphafold_build/

    # Build chemical components database (this binary was installed by pip).
    build_data

%environment
    # To work around a known XLA issue causing the compilation time to greatly
    # increase, the following environment variable setting XLA flags must be enabled
    # when running AlphaFold 3. Note that if using CUDA capability 7 GPUs, it is
    # necessary to set the following XLA_FLAGS value instead:
    # ENV XLA_FLAGS="--xla_disable_hlo_passes=custom-kernel-fusion-rewriter"
    # (no need to disable gemm in that case as it is not supported for such GPU).
    XLA_FLAGS="--xla_disable_hlo_passes=custom-kernel-fusion-rewriter --xla_gpu_enable_triton_gemm=false"
    # Memory settings used for folding up to 5,120 tokens on A100 80 GB.
    XLA_PYTHON_CLIENT_PREALLOCATE=true
    XLA_CLIENT_MEM_FRACTION=0.95

%test
    (jackhmmer -h && command -v run_alphafold.py) > /dev/null

%runscript
    run_alphafold.py "$@" 
